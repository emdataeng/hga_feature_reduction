{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfe07c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler # Keep for potential future use\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "import gdown # Library to download from Google Drive\n",
    "from sklearn.impute import SimpleImputer # Import imputer\n",
    "\n",
    "# Define color codes\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "RESET = \"\\033[0m\"  # Reset to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4416e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to open the combined file SECOM_combined_dataset.csv saved locally in the folder dataset\n",
      "File successfully opened.\n"
     ]
    }
   ],
   "source": [
    "#Alternativelly use the combined SECOM dataset csv in the dataset subfolder\n",
    "# Define the dataset folder path (the files are in a subfolder called dataset)\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_folder = Path('dataset')\n",
    "dataset_filename= 'SECOM_combined_dataset.csv'\n",
    "\n",
    "print(f\"Attempting to open the combined file {dataset_filename} saved locally in the folder {dataset_folder}\")\n",
    "try:\n",
    "     output_file = dataset_folder / dataset_filename\n",
    "     print(f'File successfully opened.')\n",
    "except FileNotFoundError as e:\n",
    "     print(f'File not found: {e}')\n",
    "except Exception as e:\n",
    "     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4797a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from dataset\\SECOM_combined_dataset.csv with shape: (1567, 591)\n",
      "\n",
      "First 5 rows of loaded data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0    3030.93    2564.00  2187.7333  1411.1265     1.3602      100.0   \n",
      "1    3095.78    2465.14  2230.4222  1463.6606     0.8294      100.0   \n",
      "2    2932.61    2559.94  2186.4111  1698.0172     1.5102      100.0   \n",
      "3    2988.72    2479.90  2199.0333   909.7926     1.3204      100.0   \n",
      "4    3032.24    2502.87  2233.3667  1326.5200     1.5334      100.0   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_581  feature_582  \\\n",
      "0    97.6133     0.1242     1.5005     0.0162  ...          NaN       0.5005   \n",
      "1   102.3433     0.1247     1.4966    -0.0005  ...     208.2045       0.5019   \n",
      "2    95.4878     0.1241     1.4436     0.0041  ...      82.8602       0.4958   \n",
      "3   104.2367     0.1217     1.4882    -0.0124  ...      73.8432       0.4990   \n",
      "4   100.3967     0.1235     1.5031    -0.0031  ...          NaN       0.4800   \n",
      "\n",
      "   feature_583  feature_584  feature_585  feature_586  feature_587  \\\n",
      "0       0.0118       0.0035       2.3630          NaN          NaN   \n",
      "1       0.0223       0.0055       4.4447       0.0096       0.0201   \n",
      "2       0.0157       0.0039       3.1745       0.0584       0.0484   \n",
      "3       0.0103       0.0025       2.0544       0.0202       0.0149   \n",
      "4       0.4766       0.1045      99.3032       0.0202       0.0149   \n",
      "\n",
      "   feature_588  feature_589  label  \n",
      "0          NaN          NaN     -1  \n",
      "1       0.0060     208.2045     -1  \n",
      "2       0.0148      82.8602      1  \n",
      "3       0.0044      73.8432     -1  \n",
      "4       0.0044      73.8432     -1  \n",
      "\n",
      "[5 rows x 591 columns]\n",
      "\n",
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 591 entries, feature_0 to label\n",
      "dtypes: float64(590), int64(1)\n",
      "memory usage: 7.1 MB\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Data using Pandas (Assuming Header IS Present) ---\n",
    "try:\n",
    "    # FIX: Remove header=None to let Pandas read the first row as header\n",
    "    data = pd.read_csv(output_file)\n",
    "    print(f\"Data loaded successfully from {output_file} with shape: {data.shape}\")\n",
    "    # Display first few rows and info to check data types\n",
    "    print(\"\\nFirst 5 rows of loaded data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    data.info()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load data from {output_file}: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5978721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature names extracted from header: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']... (Total: 590)\n",
      "Features shape after cleaning: (1567, 590)\n",
      "Number of missing labels to be imputed: 0\n",
      "Target shape after cleaning: (1567,)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Prepare Data ---\n",
    "if data.shape[1] > 1:\n",
    "    # Assume last column is target 'y', all others are features 'X'\n",
    "    feature_names = data.columns[:-1].tolist() # Get actual feature names from header\n",
    "    X_df = data[feature_names] # Select feature columns using names\n",
    "    y_series = data.iloc[:, -1] # Select target column by position\n",
    "\n",
    "    print(f\"\\nFeature names extracted from header: {feature_names[:5]}... (Total: {len(feature_names)})\")\n",
    "\n",
    "    # --- Keep Robust Cleaning Steps ---\n",
    "    # Convert non-numeric strings to numeric, coercing errors, otherwise-> NaN\n",
    "    X_df_numeric = X_df.apply(pd.to_numeric, errors='coerce')\n",
    "    y_series_numeric = pd.to_numeric(y_series, errors='coerce')\n",
    "\n",
    "    # Handle potential NaN values resulting from coercion or missing values in original file\n",
    "    imputer_X = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer_X.fit_transform(X_df_numeric)\n",
    "\n",
    "    missing_labels_count = y_series_numeric.isna().sum()\n",
    "    \n",
    "    imputer_y = SimpleImputer(strategy='most_frequent') #changed strategy from mean to most frequent since we have binary labels\n",
    "    y_imputed = imputer_y.fit_transform(y_series_numeric.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Check for NaNs after imputation (should only happen if a whole column was non-numeric/NaN)\n",
    "    if np.isnan(X_imputed).any() or np.isnan(y_imputed).any():\n",
    "        print(\"Warning: NaNs still present after imputation. Check columns with all invalid values.\")\n",
    "        # Consider more advanced imputation or dropping problematic columns/rows if this occurs\n",
    "\n",
    "    X = X_imputed\n",
    "    y = y_imputed\n",
    "\n",
    "    print(f\"Features shape after cleaning: {X.shape}\")\n",
    "    \n",
    "    print(f\"Number of missing labels to be imputed: {missing_labels_count}\")\n",
    "    print(f\"Target shape after cleaning: {y.shape}\")\n",
    "    n_features_loaded = X.shape[1] # Keep track of the number of features\n",
    "\n",
    "else:\n",
    "    print(\"Error: Loaded data has only one column. Cannot separate features and target.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2814883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training features shape: (1096, 590)\n",
      "Validation features shape: (471, 590)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. Split Data for Fitness Evaluation ---\n",
    "# Using the cleaned X and y, with stratify helps maintain the proportion of class labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "n_features = X_train.shape[1] # Use the actual number of features\n",
    "print(f\"\\nTraining features shape: {X_train.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065044e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The expected number of selected features is d âŠ† n_features, this constraint must be set up since the first population\n",
    "# to make more likely for the algorithm to focus on small subsets instead of larger ones in further generations.\n",
    "#We set the chance of each gene being 1 in the initial population P to a value of d/D\n",
    "def initialize_population(d, pop_size, n_features):\n",
    "    probability_for_1 = d/n_features\n",
    "    probability_for_0 = 1 - probability_for_1\n",
    "    \n",
    "    print(f'-Building Initial population of size: {pop_size} with approximately {d} features per individual')\n",
    "    \n",
    "    pop = np.random.choice([0, 1], size=(pop_size, n_features), p=[probability_for_0, probability_for_1])    \n",
    "    \n",
    "    # Ensure initial individuals are not all zeros\n",
    "    for i in range(pop_size):\n",
    "        if not pop[i].any:\n",
    "            #then randomly sets one feature to 1.\n",
    "            pop[i, np.random.randint(0, n_features)] = 1\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1e1e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=15, # Reduced from 50\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1) # Use n_jobs=-1 for parallelization\n",
    "# --- TUNING POINT ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fae1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Building Initial population of size: 10 with approximately 50 features per individual\n",
      "\n",
      "Individual sample: [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "\n",
      "Number Selected features: 52\n",
      "\n",
      "Y predicted: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "\n",
      "MSE: 0.27176220806794055\n",
      "\n",
      "f1_SCORE: 0.058823529411764705\n"
     ]
    }
   ],
   "source": [
    "d=50\n",
    "pop_size =10\n",
    "\n",
    "population = initialize_population(d,pop_size, n_features)\n",
    "individual= population[0]\n",
    "print(f'\\nIndividual sample: {individual}')\n",
    "\n",
    "individual = np.array(individual)  #Ensure it's a NumPy array\n",
    "selected_indices = np.where(individual == 1)[0] # Get indices where bit is 1\n",
    "num_selected_features = len(selected_indices)\n",
    "print(f'\\nNumber Selected features: {num_selected_features}')\n",
    "\n",
    "\n",
    "\n",
    "# Select corresponding columns from train/validation sets\n",
    "X_train_sel = X_train[:, selected_indices]\n",
    "X_val_sel = X_val[:, selected_indices]\n",
    "\n",
    "try:        \n",
    "    model.fit(X_train_sel, y_train)\n",
    "    y_pred = model.predict(X_val_sel)\n",
    "\n",
    "    print(f'\\nY predicted: {y_pred}')\n",
    "    \n",
    "    # Fitness = Negative MSE (maximization) - Penalty for feature count\n",
    "    #mse = mean_squared_error(y_val, y_pred)        \n",
    "    #fitness = -mse - penalty_coef * num_selected_features\n",
    "    score = mean_squared_error(y_val, y_pred)\n",
    "    print(f'\\nMSE: {score}')        \n",
    "\n",
    "    #f1 score more suitable for imbalanced (binary) datsaet\n",
    "    #penalty discourages solutions that are significantly larger or smaller than the target subset size \n",
    "    score = f1_score(y_val,y_pred,average='binary', pos_label=1)\n",
    "    print(f'\\nf1_SCORE: {score}')        \n",
    "    #penalty = penalty_coef*abs(num_selected_features - num_desired_features)\n",
    "    \n",
    "    #fitness = score - penalty\n",
    "\n",
    "except ValueError as e:\n",
    "    # Catch potential errors during fitting/prediction if data issues remain\n",
    "    print(f\"Error during model fitting/prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a2e07ab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
